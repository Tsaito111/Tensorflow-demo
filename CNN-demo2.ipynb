{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24093298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "step 0, accuracy 0.06\n",
      "step 500, accuracy 0.19\n",
      "step 1000, accuracy 0.28\n",
      "step 1500, accuracy 0.31\n",
      "step 2000, accuracy 0.19\n",
      "step 2500, accuracy 0.38\n",
      "step 3000, accuracy 0.34\n",
      "step 3500, accuracy 0.28\n",
      "step 4000, accuracy 0.19\n",
      "step 4500, accuracy 0.34\n",
      "step 5000, accuracy 0.34\n",
      "step 5500, accuracy 0.38\n",
      "step 6000, accuracy 0.28\n",
      "step 6500, accuracy 0.34\n",
      "step 7000, accuracy 0.28\n",
      "step 7500, accuracy 0.56\n",
      "step 8000, accuracy 0.31\n",
      "step 8500, accuracy 0.19\n",
      "step 9000, accuracy 0.38\n",
      "step 9500, accuracy 0.25\n",
      "test accuracy 0.39\n"
     ]
    }
   ],
   "source": [
    "# coding: UTF-8\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# 再現性の確保のために乱数シードを固定（数値は何でもよい）\n",
    "tf.set_random_seed(12345)\n",
    "\n",
    "# 入力データ\n",
    "# MNISTのワンホット表現での読み込み\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# （0） 入力画像\n",
    "x = tf.placeholder(tf.float32, name='x')\n",
    "\n",
    "# （1） サイズ変更\n",
    "x_1 = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "# （2） 畳み込み\n",
    "# ランダムカーネル\n",
    "k_0 = tf.Variable(tf.truncated_normal([4, 4, 1, 10], mean=0.0, stddev=0.1))\n",
    "# 畳み込み\n",
    "x_2 = tf.nn.conv2d(x_1, k_0, strides=[1, 3, 3, 1], padding='VALID')\n",
    "\n",
    "# （3） 活性化関数\n",
    "x_3 = tf.nn.relu(x_2)\n",
    "\n",
    "# （4） プーリング\n",
    "x_4 = tf.nn.max_pool(x_3, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "# （5） サイズ変更\n",
    "x_5 = tf.reshape(x_4, [-1, 160])\n",
    "\n",
    "# （6） 全結合\n",
    "# 重みとバイアス\n",
    "w_1 = tf.Variable(tf.zeros([160, 40]))\n",
    "b_1 = tf.Variable([0.1] * 40)\n",
    "# 全結合\n",
    "x_6 = tf.matmul(x_5, w_1) + b_1\n",
    "\n",
    "# （7） 活性化関数\n",
    "x_7 = tf.nn.relu(x_6)\n",
    "\n",
    "# （8） 全結合\n",
    "# 重みとバイアス\n",
    "w_2 = tf.Variable(tf.zeros([40, 10]))\n",
    "b_2 = tf.Variable([0.1] * 10)\n",
    "# 全結合\n",
    "x_8 = tf.matmul(x_7, w_2) + b_2\n",
    "\n",
    "# （9） 確率化\n",
    "y = tf.nn.softmax(x_8)\n",
    "\n",
    "# （10） 損失関数の最小化\n",
    "# 正解ラベル\n",
    "labels = tf.placeholder(tf.float32, name='labels')\n",
    "# 損失関数（交差エントロピー）と最適化処理（Adam）\n",
    "loss = -tf.reduce_sum(labels * tf.log(y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "# （11） 精度検証\n",
    "prediction_match = tf.equal(tf.argmax(y, axis=1), tf.argmax(labels, axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(prediction_match, tf.float32), name='accuracy')\n",
    "\n",
    "# パラメーター\n",
    "# バッチサイズ\n",
    "BATCH_SIZE = 32\n",
    "# 学習回数\n",
    "NUM_TRAIN = 10_000\n",
    "# 学習中の出力頻度\n",
    "OUTPUT_BY = 500\n",
    "\n",
    "# 学習の実行\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(NUM_TRAIN):\n",
    "  batch = mnist.train.next_batch(BATCH_SIZE)\n",
    "  inout = {x: batch[0], labels: batch[1]}\n",
    "  if i % OUTPUT_BY == 0:\n",
    "    train_accuracy = accuracy.eval(feed_dict=inout)\n",
    "    print('step {:d}, accuracy {:.2f}'.format(i, train_accuracy))\n",
    "  optimizer.run(feed_dict=inout)\n",
    "\n",
    "# テストデータによる精度検証\n",
    "test_accuracy = accuracy.eval(feed_dict={x: mnist.test.images, labels: mnist.test.labels})\n",
    "print('test accuracy {:.2f}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7102e704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "step 0, accuracy 0.06\n",
      "step 500, accuracy 0.62\n",
      "step 1000, accuracy 0.59\n",
      "step 1500, accuracy 0.78\n",
      "step 2000, accuracy 0.66\n",
      "step 2500, accuracy 0.78\n",
      "step 3000, accuracy 0.81\n",
      "step 3500, accuracy 0.78\n",
      "step 4000, accuracy 0.94\n",
      "step 4500, accuracy 0.81\n",
      "step 5000, accuracy 0.81\n",
      "step 5500, accuracy 0.72\n",
      "step 6000, accuracy 0.84\n",
      "step 6500, accuracy 0.94\n",
      "step 7000, accuracy 0.78\n",
      "step 7500, accuracy 0.94\n",
      "step 8000, accuracy 0.91\n",
      "step 8500, accuracy 0.84\n",
      "step 9000, accuracy 0.78\n",
      "step 9500, accuracy 0.84\n",
      "test accuracy 0.86\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/my-model'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coding: UTF-8\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# 再現性の確保のために乱数シードを固定（数値は何でもよい）\n",
    "tf.set_random_seed(12345)\n",
    "\n",
    "# 入力データ\n",
    "# MNISTのワンホット表現での読み込み\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# （0） 入力画像\n",
    "x = tf.placeholder(tf.float32, name='x')\n",
    "\n",
    "# （1） サイズ変更\n",
    "x_1 = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "# （2） 畳み込み\n",
    "# ランダムカーネル\n",
    "k_0 = tf.Variable(tf.truncated_normal([4, 4, 1, 10], mean=0.0, stddev=0.1))\n",
    "# 畳み込み\n",
    "x_2 = tf.nn.conv2d(x_1, k_0, strides=[1, 3, 3, 1], padding='VALID')\n",
    "\n",
    "# （3） 活性化関数\n",
    "x_3 = tf.nn.relu(x_2)\n",
    "\n",
    "# （4） プーリング\n",
    "x_4 = tf.nn.max_pool(x_3, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "# （5） サイズ変更\n",
    "x_5 = tf.reshape(x_4, [-1, 160])\n",
    "\n",
    "# ドロップアウト付きの全結合\n",
    "def matmul_plus_bias_with_dropout(x, w, b, p):\n",
    "  return tf.matmul(tf.nn.dropout(x, keep_prob=p), w) + b\n",
    "\n",
    "# （6） 全結合\n",
    "# 重みとバイアス\n",
    "w_1 = tf.Variable(tf.zeros([160, 40]))\n",
    "b_1 = tf.Variable([0.1] * 40)\n",
    "# ドロップアウト率\n",
    "p_1 = tf.placeholder(1.0, name='p_1')\n",
    "# 全結合\n",
    "x_6 = matmul_plus_bias_with_dropout(x_5, w_1, b_1, p_1)\n",
    "\n",
    "\n",
    "# （7） 活性化関数\n",
    "x_7 = tf.nn.relu(x_6)\n",
    "\n",
    "# （8） 全結合\n",
    "# 重みとバイアス\n",
    "w_2 = tf.Variable(tf.zeros([40, 10]))\n",
    "b_2 = tf.Variable([0.1] * 10)\n",
    "# ドロップアウト率\n",
    "p_2 = tf.placeholder(1.0, name='p_2')\n",
    "# 全結合\n",
    "x_8 = matmul_plus_bias_with_dropout(x_7, w_2, b_2, p_2)\n",
    "\n",
    "\n",
    "# （9） 確率化\n",
    "y = tf.nn.softmax(x_8)\n",
    "\n",
    "# （10） 損失関数の最小化\n",
    "# 正解ラベル\n",
    "labels = tf.placeholder(tf.float32, name='labels')\n",
    "# 損失関数（交差エントロピー）と最適化処理（Adam）\n",
    "loss = -tf.reduce_sum(labels * tf.log(y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "# （11） 精度検証\n",
    "prediction_match = tf.equal(tf.argmax(y, axis=1), tf.argmax(labels, axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(prediction_match, tf.float32), name='accuracy')\n",
    "\n",
    "# パラメーター\n",
    "# バッチサイズ\n",
    "BATCH_SIZE = 32\n",
    "# 学習回数\n",
    "NUM_TRAIN = 10_000\n",
    "# 学習中の出力頻度\n",
    "OUTPUT_BY = 500\n",
    "# ドロップアウト率\n",
    "DROPOUT_PROB_1 = 0.2\n",
    "DROPOUT_PROB_2 = 0.5\n",
    "\n",
    "\n",
    "# 学習の実行\n",
    "sess.run(tf.global_variables_initializer())\n",
    "dropout_prob = {p_1: DROPOUT_PROB_1, p_2: DROPOUT_PROB_2}\n",
    "saver = tf.train.Saver()\n",
    "for i in range(NUM_TRAIN):\n",
    "  batch = mnist.train.next_batch(BATCH_SIZE)\n",
    "  inout = {x: batch[0], labels: batch[1]}\n",
    "  if i % OUTPUT_BY == 0:\n",
    "    train_accuracy = accuracy.eval(feed_dict={**inout, p_1: 1.0, p_2: 1.0})\n",
    "    print('step {:d}, accuracy {:.2f}'.format(i, train_accuracy))\n",
    "    # 過程の保存\n",
    "    saver.save(sess, 'models/my-model', global_step=i)\n",
    "  optimizer.run(feed_dict={**inout, **dropout_prob})\n",
    "\n",
    "# テストデータによる精度検証\n",
    "test_accuracy = accuracy.eval(feed_dict={x: mnist.test.images, labels: mnist.test.labels, p_1: 1.0, p_2: 1.0})\n",
    "print('test accuracy {:.2f}'.format(test_accuracy))\n",
    "# 最終結果の保存\n",
    "saver.save(sess, 'models/my-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54936ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
