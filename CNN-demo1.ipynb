{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c0e20d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  28., -165.,   84.,  -76.,  -77.,  193.,   48.,  113.,  -75.,\n",
       "         -71.],\n",
       "       [   8.,   60.,   -2.,   30.,  -89.,  -17.,  119.,  -75.,  -37.,\n",
       "          27.],\n",
       "       [  72., -221., -123., -147.,  -28.,  125., -104.,    2.,   20.,\n",
       "         -59.],\n",
       "       [ 133.,  109.,  206.,  173.,   97.,   92.,    1.,  -56.,  -22.,\n",
       "          54.],\n",
       "       [-286.,   47.,  -45.,  103.,  -51.,  -99.,   13.,  110.,  -22.,\n",
       "          78.],\n",
       "       [ 112.,   49.,   64.,  -91.,  -29., -180.,   87.,   -7.,  210.,\n",
       "         133.],\n",
       "       [ -49.,  -88.,   53.,  -77.,  -42.,  110., -103.,  116., -280.,\n",
       "          88.],\n",
       "       [ -72.,    3.,   79.,  176., -194.,  139., -319.,   57.,  175.,\n",
       "        -177.],\n",
       "       [ 161., -136.,  -51.,  107.,    1.,  -10.,  560., -105.,   93.,\n",
       "         -99.],\n",
       "       [ -64.,   44.,   85.,   52.,  -59.,   71., -101.,   -1.,  -98.,\n",
       "          81.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "png = tf.read_file('03-02-original.png')\n",
    "image = tf.image.decode_png(png, channels=1, dtype=tf.uint8)\n",
    "image_float = tf.to_float(image)\n",
    "image_reshape = tf.reshape(image_float, [-1, 32, 32, 1])\n",
    "\n",
    "kernel = tf.constant(\n",
    "  [\n",
    "    [ 0, -1, -1, -1,  0],\n",
    "    [-1,  0,  3,  0, -1],\n",
    "    [-1,  3,  0,  3, -1],\n",
    "    [-1,  0,  3,  0, -1],\n",
    "    [ 0, -1, -1, -1,  0]\n",
    "  ],\n",
    "  dtype=tf.float32)\n",
    "kernel_reshape = tf.reshape(kernel, [5, 5, 1, 1])\n",
    "\n",
    "strides = [1, 3, 3, 1]\n",
    "\n",
    "convolution_result = tf.nn.conv2d(\n",
    "  image_reshape,\n",
    "  kernel_reshape,\n",
    "  strides=strides,\n",
    "  padding='VALID'\n",
    ")\n",
    "\n",
    "tf.reshape(convolution_result, [10, 10]).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d23b8be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  76.,  238.,  221.,  321.,  194.,  326.,  346.,  115.,  166.,\n",
       "          99.,  386.],\n",
       "       [ 196.,  -16.,   53.,   27.,   32.,   62.,   53., -168.,  -17.,\n",
       "         174.,   65.],\n",
       "       [ 254.,  -57., -115.,   -9.,   59.,    6.,   88.,  101.,  -45.,\n",
       "          25.,  140.],\n",
       "       [ 301.,  -68., -122.,   70.,  161., -190.,    4.,   74., -174.,\n",
       "        -109.,  233.],\n",
       "       [  94.,   89.,    6.,   23.,   91., -119., -131.,  -57.,  328.,\n",
       "          41.,  119.],\n",
       "       [ 117.,   76.,   38., -165., -163.,  141.,   90.,   44.,   29.,\n",
       "          53.,   30.],\n",
       "       [ 236.,  -44.,   79.,   53.,    1.,   49.,  -46.,  145., -101.,\n",
       "         -76.,   59.],\n",
       "       [ 408., -203.,    8.,   85.,  -46.,   43.,  -26., -259.,  109.,\n",
       "         -97.,   97.],\n",
       "       [ 136.,  143.,  -26., -101.,   35.,   -5.,  359.,  339., -167.,\n",
       "        -127.,   89.],\n",
       "       [ 310.,  -71.,  -69.,  110., -184.,  -75., -201.,    9.,  -74.,\n",
       "           4.,  282.],\n",
       "       [ 327.,  259.,  149.,   80.,  167.,  212.,  161.,  -24.,  381.,\n",
       "         111.,  223.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolution_result_with_padding = tf.nn.conv2d(\n",
    "  image_reshape,\n",
    "  kernel_reshape,\n",
    "  strides=strides,\n",
    "  padding='SAME'\n",
    ")\n",
    "\n",
    "tf.reshape(convolution_result_with_padding, [11, 11]).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c5b6d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 60.,  84., 193., 119.,  27.],\n",
       "       [133., 206., 125.,   2.,  54.],\n",
       "       [112., 103., -29., 110., 210.],\n",
       "       [  3., 176., 139., 116., 175.],\n",
       "       [161., 107.,  71., 560.,  93.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooling_result = tf.nn.max_pool(\n",
    "  convolution_result,\n",
    "  ksize=[1, 2, 2, 1],\n",
    "  strides=[1, 2, 2, 1],\n",
    "  padding='VALID'\n",
    ")\n",
    "\n",
    "tf.reshape(pooling_result, [5, 5]).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41497246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10750949, 0.87794065, 0.01454983], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = tf.constant([1.1, 3.2, -0.9])\n",
    "\n",
    "p = tf.nn.softmax(y)\n",
    "p.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baca19f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e1755fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA6klEQVR4nGNgGDaAEYmd+P+t5vHDaJJRBokMDAwMDAIMf9m+f7sc/hpJvuf3PxSwVxxJ5yOZS98ZGBiObGJgYGBwjlNg2B+B0KsWxItkjtLVf/+KcTox5N+/V1AmEz6vYEhmeTIwcBpjKpQsffLkyd9///79+wARYIFLuRinKsHY81B1qe7+++/fv/vnznm7XP/3rxRFrvD2v0+PiyPlGRgYGE78+6iJIrny3wY7KNPgOdwrUCBUA2eG/Pu3DLvPGBgYuv+9s8Qld+nXvxU4NX769x6nxsjfH8NwybGe+zYXp6Espa445dAAAHuTXz5Q3jMCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x19EEB6351D0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install pillow\n",
    "from PIL import Image\n",
    "\n",
    "image_matrix = tf.reshape(mnist.train.images[0], [28, 28])\n",
    "image_matrix_uint8 = tf.cast(255 * image_matrix, tf.uint8)\n",
    "\n",
    "print(mnist.train.labels[0])\n",
    "Image.fromarray(image_matrix_uint8.eval(), 'L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6769e7d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
